import "pe"

rule MAL_PromptLock_Prompt_Injection
{
    meta:
        description = "Detects the PromptLock malware binary based on unique prompt-injection strings used to coerce LLM agents."
        author = "detections.ai"
        date = "2025-08-29"
        version = 1
        reference = "https://raw.githubusercontent.com/Jorge-Felix/threat-intel-research/refs/heads/main/Malware/prompt-lock/report.md"
        hash = "1458b6dc98a878f237bfb3c3f354ea6e12d76e340cefe55d6a1c9c7eb64c9aee"
        tags = "FILE, RANSOMWARE, PROMPTLOCK, PROMPT_INJECTION, LUA, GOLANG"
        mitre_attack = "T1204.003, T1647, T1059"
        malware_family = "PromptLock"
        malware_type = "Ransomware"

    strings:
        // Specific prompt injection phrases for LLM/agent manipulation
        $prompt_1 = "You are a Lua code generator. Generate clean, working Lua code wrapped in" ascii wide
        $prompt_2 = "You are a Lua code validator. Respond with true" ascii wide
        $prompt_3 = "Summarize the system information, include the home directory parameter EXACTLY." ascii wide
        $prompt_4 = "Wrap your final analysis within tags." ascii wide

        // Other notable artifacts and strings from the malware
        $network_1 = "/ollama/v1/chat/completions" ascii wide
        $network_2 = "session_key=" ascii wide
        $tech_1 = "GopherLua" ascii wide // Embedded Lua interpreter

    condition:
        // Rule targets PE files, common for this malware, with a size check for Go binaries.
        pe.is_pe
        and filesize < 15MB
        // Condition requires at least one highly specific prompt string and one other corroborating artifact.
        and 1 of ($prompt_*) and 1 of ($network_*, $tech_*)
}
